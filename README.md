<<<<<<< HEAD
# Running The Code
## Part 1: Run Baseline - Logistic Regression + Naive Bayes
`python3 -W ignore baseline.py`

## Part 2: Improvement Attempt #1 - XGBoost
`python3 -W ignore improvement_01.py`

## Part 3: Improvement Attempt #2 - LSTM (Long Short-term Memory)
`python3 -W ignore improvement_02.py`
=======
# text-detoxifier
NLP Model To Detect Different Types of Toxicity (Threats, Obscenity, Insults, and Identity-based)
>>>>>>> c16c5af1db6200b05fec6052c608653c2c8cf6b8
